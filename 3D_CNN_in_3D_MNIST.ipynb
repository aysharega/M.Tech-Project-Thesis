{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D CNN in 3D MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORwF3u7Z1158X83ryC+qH1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aysharega/M.Tech-Project-Thesis/blob/main/3D_CNN_in_3D_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_ui3q_5znSZ3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "2HkvG9MroJH1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(\"/content/full_dataset_vectors.h5\", \"r\") as hf:    \n",
        "    # Split the data into training/test features/targets\n",
        "    x_train = hf[\"X_train\"][:]\n",
        "    y_train = hf[\"y_train\"][:]\n",
        "    x_test = hf[\"X_test\"][:] \n",
        "    y_test = hf[\"y_test\"][:]\n",
        "\n",
        "threshold, upper, lower = 0.2, 1, 0\n",
        "X_train = np.where(X_train>threshold, upper, lower)\n",
        "X_test = np.where(X_test>threshold, upper, lower)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 1, 16,16,16)\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, 16,16,16)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_train_onehot = onehot_encoder.fit_transform(y_train.reshape(len(y_train), 1))\n",
        "y_test_onehot = onehot_encoder.transform(y_test.reshape(len(y_test), 1))\n",
        "\n",
        "print(\"x_train\", x_train.shape)\n",
        "print(\"y_train\", y_train.shape)\n",
        "print(\"y_train_onehot\", y_train_onehot.shape)\n",
        "\n",
        "print(\"x_test\", x_test.shape)\n",
        "print(\"y_test\", y_test.shape)\n",
        "print(\"y_test_onehot\", y_test_onehot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIuhRtSRslZl",
        "outputId": "62d05821-ab6a-4f5f-fbcb-9bd6a53dee4a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train (10000, 1, 16, 16, 16)\n",
            "y_train (10000,)\n",
            "y_train_onehot (10000, 10)\n",
            "x_test (2000, 1, 16, 16, 16)\n",
            "y_test (2000,)\n",
            "y_test_onehot (2000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_idx = random.randint(0, x_train.shape[0])\n",
        "plot_img_3d = np.squeeze(x_train[plot_idx])\n",
        "plot_label = y_train[plot_idx]\n",
        "\n",
        "plot_data = []\n",
        "for x in range(0,16):\n",
        "    for y in range(0,16):\n",
        "        for z in range(0,16):\n",
        "            val = plot_img_3d[x,y,z]\n",
        "            plot_data.append([x,y,z,val])\n",
        "\n",
        "plot_df = pd.DataFrame(plot_data, columns=[\"x\", \"y\", \"z\", \"val\"])\n",
        "plot_df = plot_df.loc[plot_df[\"val\"] > 0]\n",
        "fig = go.Figure(data=[go.Scatter3d(x=plot_df['x'], y=plot_df['y'], z=plot_df['z'],\n",
        "                                   mode='markers',\n",
        "                                   marker=dict(\n",
        "                                   size=4,       \n",
        "                                   colorscale='Viridis',\n",
        "                                   opacity=0.8))])\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "1KL5YsvEtPat",
        "outputId": "bb19acf8-7467-4aff-94b0-6a283520bb0d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"610eb7f1-89da-4ed1-8e8c-d94447738e9b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"610eb7f1-89da-4ed1-8e8c-d94447738e9b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '610eb7f1-89da-4ed1-8e8c-d94447738e9b',\n",
              "                        [{\"marker\": {\"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"opacity\": 0.8, \"size\": 4}, \"mode\": \"markers\", \"type\": \"scatter3d\", \"x\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], \"y\": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 10, 10, 11, 11, 11, 11, 11, 11, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 11, 11, 12, 12, 12, 12, 12, 12, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 6, 6, 7, 7, 7, 7, 7, 7, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 15, 15, 15, 15, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15], \"z\": [5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 6, 7, 8, 10, 5, 6, 7, 8, 10, 5, 6, 7, 8, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 8, 9, 10, 8, 9, 10, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('610eb7f1-89da-4ed1-8e8c-d94447738e9b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    layers.Conv3D(8, (3,3,3), activation='relu', padding='same', input_shape=(1, 16,16,16)),\n",
        "    layers.Conv3D(16, (3,3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling3D((2,2,2), padding='same'),\n",
        "    \n",
        "    layers.Conv3D(32, (3,3,3), activation='relu', padding='same'),\n",
        "    layers.Conv3D(64, (3,3,3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling3D((2,2,2), padding='same'),\n",
        "    \n",
        "    layers.Conv3D(16, (3,3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.GlobalAveragePooling3D(),\n",
        "    layers.Flatten(),\n",
        "    \n",
        "    layers.Dense(units=1024, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(units=256, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(units=10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "T-fte7eetaw4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jf1XV84thGK",
        "outputId": "d4d95857-249f-481a-d525-d57d8e374fe2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 1, 16, 16, 8)      3464      \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 1, 16, 16, 16)     3472      \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 1, 8, 8, 16)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 1, 8, 8, 32)       13856     \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 1, 8, 8, 64)       55360     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 1, 4, 4, 64)      0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 1, 4, 4, 16)       27664     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 1, 4, 4, 16)      64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " global_average_pooling3d (G  (None, 16)               0         \n",
            " lobalAveragePooling3D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              17408     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386,258\n",
            "Trainable params: 386,226\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=x_train, y=y_train_onehot, batch_size=128, epochs=50, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH1C-tUGtoTm",
        "outputId": "5f936fbb-b9a3-4518-a6b5-3fdb992ab2d4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 25s 391ms/step - loss: 1.9808 - acc: 0.2715 - val_loss: 2.2376 - val_acc: 0.1275\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 25s 391ms/step - loss: 1.4886 - acc: 0.4679 - val_loss: 2.1766 - val_acc: 0.2540\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 25s 390ms/step - loss: 1.2300 - acc: 0.5630 - val_loss: 1.8151 - val_acc: 0.3720\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 1.1076 - acc: 0.6101 - val_loss: 1.5001 - val_acc: 0.5695\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 24s 389ms/step - loss: 1.0489 - acc: 0.6345 - val_loss: 1.3772 - val_acc: 0.5600\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 26s 409ms/step - loss: 0.9848 - acc: 0.6586 - val_loss: 1.2553 - val_acc: 0.5695\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.9542 - acc: 0.6591 - val_loss: 1.1964 - val_acc: 0.5845\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 26s 406ms/step - loss: 0.9110 - acc: 0.6771 - val_loss: 1.0504 - val_acc: 0.6355\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.8826 - acc: 0.6841 - val_loss: 1.1913 - val_acc: 0.6020\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.8611 - acc: 0.6933 - val_loss: 1.4378 - val_acc: 0.5920\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 24s 387ms/step - loss: 0.8459 - acc: 0.6973 - val_loss: 1.1125 - val_acc: 0.6255\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.8153 - acc: 0.7067 - val_loss: 1.2616 - val_acc: 0.6000\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.8031 - acc: 0.7140 - val_loss: 1.0940 - val_acc: 0.6570\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 24s 387ms/step - loss: 0.7813 - acc: 0.7145 - val_loss: 1.2647 - val_acc: 0.5660\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.7665 - acc: 0.7204 - val_loss: 1.1971 - val_acc: 0.6300\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 25s 390ms/step - loss: 0.7372 - acc: 0.7345 - val_loss: 1.6399 - val_acc: 0.6245\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.7110 - acc: 0.7452 - val_loss: 1.5754 - val_acc: 0.5490\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 26s 409ms/step - loss: 0.6874 - acc: 0.7541 - val_loss: 1.2802 - val_acc: 0.6255\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.6634 - acc: 0.7638 - val_loss: 1.3035 - val_acc: 0.6560\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 24s 389ms/step - loss: 0.6424 - acc: 0.7679 - val_loss: 1.3664 - val_acc: 0.6455\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.6074 - acc: 0.7846 - val_loss: 1.1931 - val_acc: 0.6265\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 24s 389ms/step - loss: 0.5967 - acc: 0.7850 - val_loss: 1.2522 - val_acc: 0.6265\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.5961 - acc: 0.7891 - val_loss: 2.1005 - val_acc: 0.5745\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.5443 - acc: 0.8056 - val_loss: 1.5821 - val_acc: 0.6375\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 26s 407ms/step - loss: 0.5392 - acc: 0.8092 - val_loss: 1.1578 - val_acc: 0.6545\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 24s 386ms/step - loss: 0.5064 - acc: 0.8183 - val_loss: 1.7012 - val_acc: 0.5740\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 24s 386ms/step - loss: 0.4706 - acc: 0.8354 - val_loss: 1.4012 - val_acc: 0.6520\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 26s 406ms/step - loss: 0.4721 - acc: 0.8326 - val_loss: 1.3607 - val_acc: 0.6670\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 26s 406ms/step - loss: 0.4328 - acc: 0.8470 - val_loss: 1.6024 - val_acc: 0.6085\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.4592 - acc: 0.8370 - val_loss: 1.3775 - val_acc: 0.6720\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.4014 - acc: 0.8602 - val_loss: 1.3503 - val_acc: 0.6430\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 26s 407ms/step - loss: 0.3818 - acc: 0.8656 - val_loss: 1.5523 - val_acc: 0.6275\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.3770 - acc: 0.8652 - val_loss: 1.7425 - val_acc: 0.6200\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.3442 - acc: 0.8780 - val_loss: 1.6226 - val_acc: 0.6450\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 24s 387ms/step - loss: 0.3673 - acc: 0.8696 - val_loss: 1.6687 - val_acc: 0.6390\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.3085 - acc: 0.8889 - val_loss: 1.6567 - val_acc: 0.6445\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 24s 387ms/step - loss: 0.2944 - acc: 0.8956 - val_loss: 1.6464 - val_acc: 0.6665\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.2965 - acc: 0.8964 - val_loss: 1.9891 - val_acc: 0.6025\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.2626 - acc: 0.9068 - val_loss: 2.0067 - val_acc: 0.6385\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.2536 - acc: 0.9103 - val_loss: 2.8653 - val_acc: 0.5505\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 26s 407ms/step - loss: 0.2421 - acc: 0.9141 - val_loss: 2.1950 - val_acc: 0.6330\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.2286 - acc: 0.9206 - val_loss: 1.9006 - val_acc: 0.6390\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 24s 388ms/step - loss: 0.2174 - acc: 0.9235 - val_loss: 2.1797 - val_acc: 0.6110\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 26s 409ms/step - loss: 0.2004 - acc: 0.9276 - val_loss: 1.9400 - val_acc: 0.6670\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.2115 - acc: 0.9256 - val_loss: 1.7805 - val_acc: 0.6600\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 25s 391ms/step - loss: 0.1855 - acc: 0.9377 - val_loss: 2.1512 - val_acc: 0.6170\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 25s 390ms/step - loss: 0.2075 - acc: 0.9312 - val_loss: 1.9528 - val_acc: 0.6280\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 26s 409ms/step - loss: 0.1756 - acc: 0.9400 - val_loss: 2.1748 - val_acc: 0.6420\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 26s 409ms/step - loss: 0.1670 - acc: 0.9401 - val_loss: 2.0670 - val_acc: 0.6425\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 25s 390ms/step - loss: 0.1253 - acc: 0.9549 - val_loss: 2.0762 - val_acc: 0.6620\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f697db30690>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=x_test, y=y_test_onehot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pr90Y48tseC",
        "outputId": "3a7e67a8-875f-4c38-d977-bf2ea8af6bf2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3/63 [>.............................] - ETA: 2s - loss: 1.3539 - acc: 0.7188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 37ms/step - loss: 1.9073 - acc: 0.6670\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.907344937324524, 0.6669999957084656]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}